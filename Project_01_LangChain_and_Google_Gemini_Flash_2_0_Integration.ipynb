{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyPF6fZn8tBIJM/RmZmUZxB2",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/EshaAmjad26/Projects-on-Colab/blob/main/Project_01_LangChain_and_Google_Gemini_Flash_2_0_Integration.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Project 01: LangChain and Google Gemini Flash 2.0 Integration  "
      ],
      "metadata": {
        "id": "PR-AmO3HZDWs"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "###    1. Set up your Colab environment by installing the required libraries and configuring the Gemini Flash model."
      ],
      "metadata": {
        "id": "LJDKubIvi7wi"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "iTFVbuz-Mv08",
        "outputId": "f6b1cc7e-6f11-4f50-d88f-8fc2f8ecc92e"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: langchain in /usr/local/lib/python3.10/dist-packages (0.3.12)\n",
            "Collecting langchain-google-genai\n",
            "  Downloading langchain_google_genai-2.0.7-py3-none-any.whl.metadata (3.6 kB)\n",
            "Requirement already satisfied: PyYAML>=5.3 in /usr/local/lib/python3.10/dist-packages (from langchain) (6.0.2)\n",
            "Requirement already satisfied: SQLAlchemy<3,>=1.4 in /usr/local/lib/python3.10/dist-packages (from langchain) (2.0.36)\n",
            "Requirement already satisfied: aiohttp<4.0.0,>=3.8.3 in /usr/local/lib/python3.10/dist-packages (from langchain) (3.11.10)\n",
            "Requirement already satisfied: async-timeout<5.0.0,>=4.0.0 in /usr/local/lib/python3.10/dist-packages (from langchain) (4.0.3)\n",
            "Requirement already satisfied: langchain-core<0.4.0,>=0.3.25 in /usr/local/lib/python3.10/dist-packages (from langchain) (0.3.25)\n",
            "Requirement already satisfied: langchain-text-splitters<0.4.0,>=0.3.3 in /usr/local/lib/python3.10/dist-packages (from langchain) (0.3.3)\n",
            "Requirement already satisfied: langsmith<0.3,>=0.1.17 in /usr/local/lib/python3.10/dist-packages (from langchain) (0.2.3)\n",
            "Requirement already satisfied: numpy<2,>=1.22.4 in /usr/local/lib/python3.10/dist-packages (from langchain) (1.26.4)\n",
            "Requirement already satisfied: pydantic<3.0.0,>=2.7.4 in /usr/local/lib/python3.10/dist-packages (from langchain) (2.10.3)\n",
            "Requirement already satisfied: requests<3,>=2 in /usr/local/lib/python3.10/dist-packages (from langchain) (2.32.3)\n",
            "Requirement already satisfied: tenacity!=8.4.0,<10,>=8.1.0 in /usr/local/lib/python3.10/dist-packages (from langchain) (9.0.0)\n",
            "Collecting filetype<2.0.0,>=1.2.0 (from langchain-google-genai)\n",
            "  Downloading filetype-1.2.0-py2.py3-none-any.whl.metadata (6.5 kB)\n",
            "Requirement already satisfied: google-generativeai<0.9.0,>=0.8.0 in /usr/local/lib/python3.10/dist-packages (from langchain-google-genai) (0.8.3)\n",
            "Requirement already satisfied: aiohappyeyeballs>=2.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (2.4.4)\n",
            "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (1.3.2)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (24.3.0)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (1.5.0)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (6.1.0)\n",
            "Requirement already satisfied: propcache>=0.2.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (0.2.1)\n",
            "Requirement already satisfied: yarl<2.0,>=1.17.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (1.18.3)\n",
            "Requirement already satisfied: google-ai-generativelanguage==0.6.10 in /usr/local/lib/python3.10/dist-packages (from google-generativeai<0.9.0,>=0.8.0->langchain-google-genai) (0.6.10)\n",
            "Requirement already satisfied: google-api-core in /usr/local/lib/python3.10/dist-packages (from google-generativeai<0.9.0,>=0.8.0->langchain-google-genai) (2.19.2)\n",
            "Requirement already satisfied: google-api-python-client in /usr/local/lib/python3.10/dist-packages (from google-generativeai<0.9.0,>=0.8.0->langchain-google-genai) (2.155.0)\n",
            "Requirement already satisfied: google-auth>=2.15.0 in /usr/local/lib/python3.10/dist-packages (from google-generativeai<0.9.0,>=0.8.0->langchain-google-genai) (2.27.0)\n",
            "Requirement already satisfied: protobuf in /usr/local/lib/python3.10/dist-packages (from google-generativeai<0.9.0,>=0.8.0->langchain-google-genai) (4.25.5)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from google-generativeai<0.9.0,>=0.8.0->langchain-google-genai) (4.67.1)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.10/dist-packages (from google-generativeai<0.9.0,>=0.8.0->langchain-google-genai) (4.12.2)\n",
            "Requirement already satisfied: proto-plus<2.0.0dev,>=1.22.3 in /usr/local/lib/python3.10/dist-packages (from google-ai-generativelanguage==0.6.10->google-generativeai<0.9.0,>=0.8.0->langchain-google-genai) (1.25.0)\n",
            "Requirement already satisfied: jsonpatch<2.0,>=1.33 in /usr/local/lib/python3.10/dist-packages (from langchain-core<0.4.0,>=0.3.25->langchain) (1.33)\n",
            "Requirement already satisfied: packaging<25,>=23.2 in /usr/local/lib/python3.10/dist-packages (from langchain-core<0.4.0,>=0.3.25->langchain) (24.2)\n",
            "Requirement already satisfied: httpx<1,>=0.23.0 in /usr/local/lib/python3.10/dist-packages (from langsmith<0.3,>=0.1.17->langchain) (0.28.1)\n",
            "Requirement already satisfied: orjson<4.0.0,>=3.9.14 in /usr/local/lib/python3.10/dist-packages (from langsmith<0.3,>=0.1.17->langchain) (3.10.12)\n",
            "Requirement already satisfied: requests-toolbelt<2.0.0,>=1.0.0 in /usr/local/lib/python3.10/dist-packages (from langsmith<0.3,>=0.1.17->langchain) (1.0.0)\n",
            "Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.10/dist-packages (from pydantic<3.0.0,>=2.7.4->langchain) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.27.1 in /usr/local/lib/python3.10/dist-packages (from pydantic<3.0.0,>=2.7.4->langchain) (2.27.1)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2->langchain) (3.4.0)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2->langchain) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2->langchain) (2.2.3)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2->langchain) (2024.12.14)\n",
            "Requirement already satisfied: greenlet!=0.4.17 in /usr/local/lib/python3.10/dist-packages (from SQLAlchemy<3,>=1.4->langchain) (3.1.1)\n",
            "Requirement already satisfied: googleapis-common-protos<2.0.dev0,>=1.56.2 in /usr/local/lib/python3.10/dist-packages (from google-api-core->google-generativeai<0.9.0,>=0.8.0->langchain-google-genai) (1.66.0)\n",
            "Requirement already satisfied: cachetools<6.0,>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from google-auth>=2.15.0->google-generativeai<0.9.0,>=0.8.0->langchain-google-genai) (5.5.0)\n",
            "Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.10/dist-packages (from google-auth>=2.15.0->google-generativeai<0.9.0,>=0.8.0->langchain-google-genai) (0.4.1)\n",
            "Requirement already satisfied: rsa<5,>=3.1.4 in /usr/local/lib/python3.10/dist-packages (from google-auth>=2.15.0->google-generativeai<0.9.0,>=0.8.0->langchain-google-genai) (4.9)\n",
            "Requirement already satisfied: anyio in /usr/local/lib/python3.10/dist-packages (from httpx<1,>=0.23.0->langsmith<0.3,>=0.1.17->langchain) (3.7.1)\n",
            "Requirement already satisfied: httpcore==1.* in /usr/local/lib/python3.10/dist-packages (from httpx<1,>=0.23.0->langsmith<0.3,>=0.1.17->langchain) (1.0.7)\n",
            "Requirement already satisfied: h11<0.15,>=0.13 in /usr/local/lib/python3.10/dist-packages (from httpcore==1.*->httpx<1,>=0.23.0->langsmith<0.3,>=0.1.17->langchain) (0.14.0)\n",
            "Requirement already satisfied: jsonpointer>=1.9 in /usr/local/lib/python3.10/dist-packages (from jsonpatch<2.0,>=1.33->langchain-core<0.4.0,>=0.3.25->langchain) (3.0.0)\n",
            "Requirement already satisfied: httplib2<1.dev0,>=0.19.0 in /usr/local/lib/python3.10/dist-packages (from google-api-python-client->google-generativeai<0.9.0,>=0.8.0->langchain-google-genai) (0.22.0)\n",
            "Requirement already satisfied: google-auth-httplib2<1.0.0,>=0.2.0 in /usr/local/lib/python3.10/dist-packages (from google-api-python-client->google-generativeai<0.9.0,>=0.8.0->langchain-google-genai) (0.2.0)\n",
            "Requirement already satisfied: uritemplate<5,>=3.0.1 in /usr/local/lib/python3.10/dist-packages (from google-api-python-client->google-generativeai<0.9.0,>=0.8.0->langchain-google-genai) (4.1.1)\n",
            "Requirement already satisfied: grpcio<2.0dev,>=1.33.2 in /usr/local/lib/python3.10/dist-packages (from google-api-core[grpc]!=2.0.*,!=2.1.*,!=2.10.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,!=2.8.*,!=2.9.*,<3.0.0dev,>=1.34.1->google-ai-generativelanguage==0.6.10->google-generativeai<0.9.0,>=0.8.0->langchain-google-genai) (1.68.1)\n",
            "Requirement already satisfied: grpcio-status<2.0.dev0,>=1.33.2 in /usr/local/lib/python3.10/dist-packages (from google-api-core[grpc]!=2.0.*,!=2.1.*,!=2.10.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,!=2.8.*,!=2.9.*,<3.0.0dev,>=1.34.1->google-ai-generativelanguage==0.6.10->google-generativeai<0.9.0,>=0.8.0->langchain-google-genai) (1.62.3)\n",
            "Requirement already satisfied: pyparsing!=3.0.0,!=3.0.1,!=3.0.2,!=3.0.3,<4,>=2.4.2 in /usr/local/lib/python3.10/dist-packages (from httplib2<1.dev0,>=0.19.0->google-api-python-client->google-generativeai<0.9.0,>=0.8.0->langchain-google-genai) (3.2.0)\n",
            "Requirement already satisfied: pyasn1<0.7.0,>=0.4.6 in /usr/local/lib/python3.10/dist-packages (from pyasn1-modules>=0.2.1->google-auth>=2.15.0->google-generativeai<0.9.0,>=0.8.0->langchain-google-genai) (0.6.1)\n",
            "Requirement already satisfied: sniffio>=1.1 in /usr/local/lib/python3.10/dist-packages (from anyio->httpx<1,>=0.23.0->langsmith<0.3,>=0.1.17->langchain) (1.3.1)\n",
            "Requirement already satisfied: exceptiongroup in /usr/local/lib/python3.10/dist-packages (from anyio->httpx<1,>=0.23.0->langsmith<0.3,>=0.1.17->langchain) (1.2.2)\n",
            "Downloading langchain_google_genai-2.0.7-py3-none-any.whl (41 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m41.3/41.3 kB\u001b[0m \u001b[31m2.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading filetype-1.2.0-py2.py3-none-any.whl (19 kB)\n",
            "Installing collected packages: filetype, langchain-google-genai\n",
            "Successfully installed filetype-1.2.0 langchain-google-genai-2.0.7\n"
          ]
        }
      ],
      "source": [
        "!pip install langchain langchain-google-genai"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import langchain_google_genai as genai\n"
      ],
      "metadata": {
        "id": "Wtu5E9q7NFD_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain_google_genai import ChatGoogleGenerativeAI"
      ],
      "metadata": {
        "id": "rXWbI3FINTEM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import userdata\n",
        "GEMINI_API_KEY = userdata.get('GEMINI_API_KEY')"
      ],
      "metadata": {
        "id": "iuJWI1-PNzVE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model : ChatGoogleGenerativeAI = ChatGoogleGenerativeAI(\n",
        "    model = 'gemini-2.0-flash-exp',\n",
        "    api_key = GEMINI_API_KEY,\n",
        "    temperature = 0.7\n",
        "\n",
        ")"
      ],
      "metadata": {
        "id": "UGaBOTPqOYfg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "response = model.invoke('What is LangChain?')"
      ],
      "metadata": {
        "id": "NFvE7H3ORywG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from IPython.display import Markdown, display"
      ],
      "metadata": {
        "id": "231YpcCvXu23"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "display(Markdown(response.content))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 772
        },
        "id": "amQoJjpzStA6",
        "outputId": "5ccace0e-aa23-4302-faee-9c8621c38762"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Markdown object>"
            ],
            "text/markdown": "LangChain is a powerful framework designed to simplify the development of applications powered by large language models (LLMs). Think of it as a toolkit that provides a standardized way to interact with and chain together different components, making it easier to build complex applications that leverage the power of LLMs.\n\nHere's a breakdown of what makes LangChain important and what it offers:\n\n**Key Concepts and Benefits:**\n\n* **LLM Abstraction:** LangChain provides a common interface to work with different LLMs (like OpenAI's GPT models, Google's PaLM, and open-source models). This means you can easily swap between models without rewriting large portions of your code.\n* **Chaining and Composition:** The core concept of LangChain is the ability to chain together different components to create more complex workflows. You can combine LLMs with other tools, data sources, and logic to achieve more sophisticated tasks.\n* **Components:** LangChain offers a wide range of pre-built components that you can use in your applications, including:\n    * **Models:** Wrappers for various LLMs.\n    * **Prompts:** Tools for creating and managing prompts for LLMs.\n    * **Indexes:** Tools for indexing and retrieving data for use with LLMs.\n    * **Chains:** Mechanisms for combining multiple components into a workflow.\n    * **Agents:** Tools that allow LLMs to interact with external tools and data.\n    * **Memory:** Mechanisms for managing conversation history and context.\n    * **Callbacks:** Tools for monitoring and logging the execution of chains.\n* **Flexibility and Customization:** While LangChain offers pre-built components, it's designed to be highly flexible. You can easily extend and customize the framework to meet your specific needs.\n* **Community and Ecosystem:** LangChain has a vibrant and active community that contributes to its development and provides support to users.\n\n**Why Use LangChain?**\n\n* **Reduced Complexity:** Building applications with LLMs from scratch can be complex and require significant expertise. LangChain simplifies this process by providing pre-built components and a standardized framework.\n* **Faster Development:** By leveraging existing components and abstractions, you can significantly speed up the development process.\n* **Improved Maintainability:** The modular nature of LangChain makes it easier to maintain and update your applications.\n* **Experimentation:** LangChain makes it easier to experiment with different LLMs, prompts, and workflows, allowing you to quickly iterate and find the best solutions.\n* **Integration:** LangChain integrates with various tools and services, allowing you to build more powerful and versatile applications.\n\n**Common Use Cases:**\n\n* **Chatbots and Conversational AI:** Building more sophisticated chatbots with memory and context awareness.\n* **Question Answering Systems:** Creating systems that can answer questions based on large amounts of data.\n* **Text Summarization:** Automating the process of summarizing lengthy documents.\n* **Code Generation:** Generating code snippets based on natural language instructions.\n* **Data Analysis:** Using LLMs to analyze and interpret data.\n* **Content Creation:** Generating various types of content, such as articles, blog posts, and marketing copy.\n\n**In summary, LangChain is a powerful framework that empowers developers to build sophisticated applications with LLMs by providing a set of tools, components, and abstractions. It simplifies the process of working with LLMs, enabling faster development, easier maintenance, and greater experimentation.**\n\nIf you're interested in exploring the world of LLM applications, LangChain is a valuable tool to learn and use. It provides a strong foundation for building a wide range of innovative and intelligent applications.\n"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "##         2. Define a prompt template and create an LLM chain using LangChain."
      ],
      "metadata": {
        "id": "gLKu7Q3Ji01G"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain_core.prompts import PromptTemplate\n",
        "from langchain.chains import LLMChain\n"
      ],
      "metadata": {
        "id": "pS8vFLL5Urrj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "template = \"\"\"Question : {question}\n",
        "Answer: Let's think about it.\n",
        "\"\"\"\n",
        "\n",
        "prompt = PromptTemplate.from_template(template)\n",
        " # Create the chain (method 1)\n",
        "chain = prompt | model\n",
        " # Create the chain (method 2)\n",
        "chain = LLMChain(prompt = prompt, llm = model)"
      ],
      "metadata": {
        "id": "nozLmVkdV_EO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##  3. Run the chain with at least three user-defined questions and display the model's responses."
      ],
      "metadata": {
        "id": "0EQBEVZLikdT"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "question1 = 'What is AI'\n",
        "chain.invoke({'question': question1})\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kr1jKJfjW3vU",
        "outputId": "c34e1771-031f-4d9a-de60-fa8530f5c7b5"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'question': 'What is AI',\n",
              " 'text': 'Okay, I\\'m ready to think about it! \\n\\nLet\\'s break down what AI is. Instead of giving a textbook definition, we can explore different facets of it:\\n\\n**At its core, AI is about making machines intelligent.** But what does \"intelligent\" mean? That\\'s where it gets tricky. We can think of it in different ways:\\n\\n* **Mimicking Human Intelligence:** This is a common way to think about AI. We\\'re trying to create machines that can do things that we consider to be \"smart\" when humans do them. This includes things like:\\n    * **Learning:** Acquiring knowledge and improving performance over time.\\n    * **Problem-solving:** Figuring out how to achieve a goal, even in new situations.\\n    * **Reasoning:** Drawing logical conclusions from information.\\n    * **Understanding language:** Processing and interpreting human communication.\\n    * **Perception:** Making sense of the world through sight, sound, and other senses.\\n* **Automating Complex Tasks:** AI can also be seen as a way to automate tasks that would normally require human intelligence. This includes things like:\\n    * **Data analysis:** Finding patterns and insights in large datasets.\\n    * **Decision-making:** Making choices based on data and rules.\\n    * **Robotics:** Controlling physical machines to perform tasks.\\n* **Adaptability and Flexibility:** A key aspect of AI is its ability to adapt to new situations and learn from its experiences. This is crucial for making systems that can operate effectively in dynamic and unpredictable environments.\\n\\n**Important Considerations:**\\n\\n* **AI is a broad field:** It encompasses many different techniques and approaches, including machine learning, deep learning, natural language processing, computer vision, and robotics.\\n* **AI is not a single thing:** There isn\\'t one \"AI\" that does everything. Instead, we have specialized AI systems designed for specific tasks.\\n* **AI is constantly evolving:** The field is rapidly advancing, with new breakthroughs and applications being developed all the time.\\n* **Ethical implications:** As AI becomes more powerful, it\\'s crucial to consider its potential ethical and societal impacts.\\n\\n**So, instead of a single definition, think of AI as a collection of technologies and approaches aimed at making machines more intelligent and capable. It\\'s about enabling machines to learn, adapt, and solve problems in ways that were previously only possible for humans.**\\n\\nWhat are your thoughts? What aspects of AI are you most interested in? Perhaps we can explore specific areas further.\\n'}"
            ]
          },
          "metadata": {},
          "execution_count": 17
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "question2 = 'What is Langchain?'\n",
        "result = chain.invoke({'question': question2})\n",
        "result"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gMnj6n9bX72J",
        "outputId": "6120bf58-d6cd-46ff-baec-5d8a20b60f1f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'question': 'What is Langchain?',\n",
              " 'text': \"Okay, let's think about Langchain. Here's a breakdown of what it is, considering different aspects:\\n\\n**Core Idea:**\\n\\n* **Framework for Building Applications with Large Language Models (LLMs):** At its heart, Langchain is a software framework designed to make it easier to develop applications that leverage the power of LLMs like GPT-3, GPT-4, and others. Think of it as a set of tools and abstractions that simplify the complex interactions with these powerful models.\\n\\n**Key Components and Concepts:**\\n\\n* **Chains:** This is a fundamental concept. Chains are sequences of calls to LLMs and other utilities. They allow you to create complex workflows, going beyond simple prompt-response interactions. For example, a chain might:\\n    1. Take user input.\\n    2. Use an LLM to analyze the input and extract key information.\\n    3. Use that information to query a database.\\n    4. Use another LLM to formulate a response based on the database results.\\n* **Models:** Langchain provides a unified interface for interacting with various LLMs from different providers (OpenAI, Google, Hugging Face, etc.). This means you don't have to write custom code for each model.\\n* **Prompts:** It offers tools for creating and managing prompts, which are instructions given to LLMs. These tools help with things like:\\n    * Prompt templating (using placeholders for variables)\\n    * Prompt selection (choosing the best prompt for a given task)\\n    * Prompt chaining (building sequences of prompts)\\n* **Indexes:** Langchain helps with indexing and retrieving information from external data sources (like text files, websites, databases). This is crucial for building LLM applications that need to work with real-world data.\\n* **Memory:** It provides mechanisms to store and retrieve previous interactions, enabling conversational applications that can remember the context of a conversation.\\n* **Agents:** This is a powerful concept where LLMs are given tools and can decide which tool to use to accomplish a goal. This enables more autonomous and flexible applications.\\n* **Callbacks:** Allows you to monitor and log the progress of your Langchain applications.\\n\\n**Why Use Langchain?**\\n\\n* **Abstraction and Simplification:** It hides a lot of the complexity of interacting with LLMs, making it easier to build applications even without deep machine learning expertise.\\n* **Modularity and Reusability:** The components of Langchain are designed to be modular and reusable, allowing you to easily compose complex applications from simpler building blocks.\\n* **Integration:** It provides integrations with various data sources, LLM providers, and other tools, making it easy to connect different parts of your application.\\n* **Rapid Prototyping:** It speeds up the development process, allowing you to quickly experiment with different ideas and iterate on your applications.\\n* **Active Development:** The Langchain project is actively developed and constantly evolving, meaning you have access to the latest features and improvements.\\n\\n**In Simple Terms:**\\n\\nImagine you're building a chatbot. Instead of manually coding everything, Langchain gives you pre-built tools to:\\n\\n* Talk to the chatbot (LLM).\\n* Remember what you've said before (Memory).\\n* Look up information in a database (Indexes).\\n* Choose the best way to answer your question (Chains/Agents).\\n\\n**In essence, Langchain is a powerful toolkit that empowers developers to harness the full potential of LLMs and build sophisticated AI-powered applications.**\\n\\nIs there anything specific you'd like to explore further about Langchain? Perhaps you're interested in a particular aspect like chains, agents, or its integration with a specific LLM provider? Let me know!\\n\"}"
            ]
          },
          "metadata": {},
          "execution_count": 18
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "question3 = \" Who is the founder of Pakistan?\"\n",
        "chain.invoke({'question': question3})"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "a7sQyyWQedPm",
        "outputId": "ce14a0f5-ba04-45e3-e29a-74ceef939dd1"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'question': ' Who is the founder of Pakistan?',\n",
              " 'text': 'Okay, I\\'m ready to think about it. The question is, \"Who is the founder of Pakistan?\" Let\\'s consider the options and the complexities involved.\\n'}"
            ]
          },
          "metadata": {},
          "execution_count": 19
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "##           4. Experiment with different prompt templates, parameters (e.g., temperature), and chain configurations to optimize responses.  "
      ],
      "metadata": {
        "id": "PkbUdAKGeTNj"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model1 :ChatGoogleGenerativeAI = ChatGoogleGenerativeAI(\n",
        "    model = 'gemini-2.0-flash-exp',\n",
        "    api_key = GEMINI_API_KEY,\n",
        "    temperature = 0.4,\n",
        "    max_tokens= 150,\n",
        ")"
      ],
      "metadata": {
        "id": "Lr-xFIs2ZThG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model2 : ChatGoogleGenerativeAI = ChatGoogleGenerativeAI(\n",
        "    model = 'gemini-2.0-flash-exp',\n",
        "    api_key = GEMINI_API_KEY,\n",
        "    temperature = 0.7,\n",
        "    max_tokens= 75\n",
        ")"
      ],
      "metadata": {
        "id": "vr8fi7yTeI_l"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "chain = prompt | model1\n",
        "question1 = \"Who is the founder of Pakistan?\"\n",
        "print(chain.invoke({'question': question1}))\n",
        "chain.invoke({'question': question1})"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZYO79Wrfe5xX",
        "outputId": "2181eb5d-0fa5-415c-d921-f2d0b18e3279"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "content='Okay, I\\'m ready to think about it. \\n\\nWhile it\\'s tempting to give a simple answer, the founding of Pakistan is a complex historical event with many key figures involved. It wasn\\'t solely the work of one person. \\n\\nHowever, the person most widely regarded as the **founder of Pakistan** is **Muhammad Ali Jinnah**. \\n\\nHe was the leader of the All-India Muslim League and played a crucial role in advocating for the creation of a separate Muslim state, which ultimately became Pakistan. He is often referred to as the \"Quaid-e-Azam\" (Great Leader) in Pakistan.\\n\\nSo, while others contributed, **Muhammad Ali Jinnah** is the figure most closely associated with' additional_kwargs={} response_metadata={'prompt_feedback': {'block_reason': 0, 'safety_ratings': []}, 'finish_reason': 'MAX_TOKENS', 'safety_ratings': [{'category': 'HARM_CATEGORY_HATE_SPEECH', 'probability': 'NEGLIGIBLE', 'blocked': False}, {'category': 'HARM_CATEGORY_DANGEROUS_CONTENT', 'probability': 'NEGLIGIBLE', 'blocked': False}, {'category': 'HARM_CATEGORY_HARASSMENT', 'probability': 'NEGLIGIBLE', 'blocked': False}, {'category': 'HARM_CATEGORY_SEXUALLY_EXPLICIT', 'probability': 'NEGLIGIBLE', 'blocked': False}]} id='run-c87a76c6-d481-4a63-b776-d8d2e1a4a5a2-0' usage_metadata={'input_tokens': 21, 'output_tokens': 150, 'total_tokens': 171, 'input_token_details': {'cache_read': 0}}\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "AIMessage(content='Okay, I\\'m thinking. \\n\\nWhile there isn\\'t one single person who \"founded\" Pakistan in the way that, say, George Washington founded the United States, the person most widely considered the **founding father** and the **driving force behind the creation of Pakistan** is **Muhammad Ali Jinnah**. \\n\\nHe was the leader of the All-India Muslim League and played a crucial role in advocating for a separate Muslim state. So, while many people contributed to the idea and the eventual formation of Pakistan, Jinnah is the figure most closely associated with its founding.\\n\\nTherefore, my answer is: **Muhammad Ali Jinnah**.\\n', additional_kwargs={}, response_metadata={'prompt_feedback': {'block_reason': 0, 'safety_ratings': []}, 'finish_reason': 'STOP', 'safety_ratings': [{'category': 'HARM_CATEGORY_HATE_SPEECH', 'probability': 'NEGLIGIBLE', 'blocked': False}, {'category': 'HARM_CATEGORY_DANGEROUS_CONTENT', 'probability': 'NEGLIGIBLE', 'blocked': False}, {'category': 'HARM_CATEGORY_HARASSMENT', 'probability': 'NEGLIGIBLE', 'blocked': False}, {'category': 'HARM_CATEGORY_SEXUALLY_EXPLICIT', 'probability': 'NEGLIGIBLE', 'blocked': False}]}, id='run-7a0244a2-409d-4589-b969-8aebb154ed02-0', usage_metadata={'input_tokens': 21, 'output_tokens': 133, 'total_tokens': 154, 'input_token_details': {'cache_read': 0}})"
            ]
          },
          "metadata": {},
          "execution_count": 22
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "chain = prompt | model2\n",
        "question2 = \"Who is the founder of Pakistan?\"\n",
        "print(chain.invoke({'question': question2}))\n",
        "chain.invoke({'question': question1})"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5viYc2UIhNJe",
        "outputId": "21dd4cbb-7673-4940-d90c-b2e0291d7c34"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "content=\"Okay, I'm ready to think about it. Who is considered the founder of Pakistan?\\n\" additional_kwargs={} response_metadata={'prompt_feedback': {'block_reason': 0, 'safety_ratings': []}, 'finish_reason': 'STOP', 'safety_ratings': [{'category': 'HARM_CATEGORY_HATE_SPEECH', 'probability': 'NEGLIGIBLE', 'blocked': False}, {'category': 'HARM_CATEGORY_DANGEROUS_CONTENT', 'probability': 'NEGLIGIBLE', 'blocked': False}, {'category': 'HARM_CATEGORY_HARASSMENT', 'probability': 'NEGLIGIBLE', 'blocked': False}, {'category': 'HARM_CATEGORY_SEXUALLY_EXPLICIT', 'probability': 'NEGLIGIBLE', 'blocked': False}]} id='run-9caf3e9b-bc50-408c-a0ac-324d262af38a-0' usage_metadata={'input_tokens': 21, 'output_tokens': 20, 'total_tokens': 41, 'input_token_details': {'cache_read': 0}}\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "AIMessage(content=\"Okay, I'm ready to think about it. \\n\\nWhile the answer might seem straightforward to some, it's worth considering the different perspectives and nuances involved. So, let's break down who is considered the founder of Pakistan.\\n\", additional_kwargs={}, response_metadata={'prompt_feedback': {'block_reason': 0, 'safety_ratings': []}, 'finish_reason': 'STOP', 'safety_ratings': [{'category': 'HARM_CATEGORY_HATE_SPEECH', 'probability': 'NEGLIGIBLE', 'blocked': False}, {'category': 'HARM_CATEGORY_DANGEROUS_CONTENT', 'probability': 'NEGLIGIBLE', 'blocked': False}, {'category': 'HARM_CATEGORY_HARASSMENT', 'probability': 'NEGLIGIBLE', 'blocked': False}, {'category': 'HARM_CATEGORY_SEXUALLY_EXPLICIT', 'probability': 'NEGLIGIBLE', 'blocked': False}]}, id='run-3d44bd9b-8f4d-4087-b0f8-72e5a5346620-0', usage_metadata={'input_tokens': 21, 'output_tokens': 50, 'total_tokens': 71, 'input_token_details': {'cache_read': 0}})"
            ]
          },
          "metadata": {},
          "execution_count": 23
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "tU1kn11HiWWR"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}